{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/Arrhythmia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstract: Distinguish between the presence and absence of cardiac arrhythmia and classify it in one of the 16 groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Information:\n",
    "\n",
    "This database contains 279 attributes, 206 of which are linear valued and the rest are nominal.\n",
    "\n",
    "Concerning the study of H. Altay Guvenir: \"The aim is to distinguish between the presence and absence of cardiac arrhythmia and to classify it in one of the 16 groups. Class 01 refers to 'normal' ECG classes 02 to 15 refers to different classes of arrhythmia and class 16 refers to the rest of unclassified ones. For the time being, there exists a computer program that makes such a classification. However there are differences between the cardiolog's and the programs classification. Taking the cardiolog's as a gold standard we aim to minimise this difference by means of machine learning tools.\"\n",
    "\n",
    "The names and id numbers of the patients were recently removed from the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Information:\n",
    "\n",
    "    -- Complete attribute documentation:\n",
    "    1 Age: Age in years , linear\n",
    "    2 Sex: Sex (0 = male; 1 = female) , nominal\n",
    "    3 Height: Height in centimeters , linear\n",
    "    4 Weight: Weight in kilograms , linear\n",
    "    5 QRS duration: Average of QRS duration in msec., linear\n",
    "    6 P-R interval: Average duration between onset of P and Q waves in msec., linear\n",
    "    7 Q-T interval: Average duration between onset of Q and offset of T waves in msec., linear\n",
    "    8 T interval: Average duration of T wave in msec., linear\n",
    "    9 P interval: Average duration of P wave in msec., linear\n",
    "    Vector angles in degrees on front plane of:, linear\n",
    "    10 QRS\n",
    "    11 T\n",
    "    12 P\n",
    "    13 QRST\n",
    "    14 J\n",
    "\n",
    "    15 Heart rate: Number of heart beats per minute ,linear\n",
    "\n",
    "    Of channel DI:\n",
    "    Average width, in msec., of: linear\n",
    "    16 Q wave\n",
    "    17 R wave\n",
    "    18 S wave\n",
    "    19 R' wave, small peak just after R\n",
    "    20 S' wave\n",
    "\n",
    "    21 Number of intrinsic deflections, linear\n",
    "\n",
    "    22 Existence of ragged R wave, nominal\n",
    "    23 Existence of diphasic derivation of R wave, nominal\n",
    "    24 Existence of ragged P wave, nominal\n",
    "    25 Existence of diphasic derivation of P wave, nominal\n",
    "    26 Existence of ragged T wave, nominal\n",
    "    27 Existence of diphasic derivation of T wave, nominal\n",
    "\n",
    "    Of channel DII:\n",
    "    28 .. 39 (similar to 16 .. 27 of channel DI)\n",
    "    Of channels DIII:\n",
    "    40 .. 51\n",
    "    Of channel AVR:\n",
    "    52 .. 63\n",
    "    Of channel AVL:\n",
    "    64 .. 75\n",
    "    Of channel AVF:\n",
    "    76 .. 87\n",
    "    Of channel V1:\n",
    "    88 .. 99\n",
    "    Of channel V2:\n",
    "    100 .. 111\n",
    "    Of channel V3:\n",
    "    112 .. 123\n",
    "    Of channel V4:\n",
    "    124 .. 135\n",
    "    Of channel V5:\n",
    "    136 .. 147\n",
    "    Of channel V6:\n",
    "    148 .. 159\n",
    "\n",
    "    Of channel DI:\n",
    "    Amplitude , * 0.1 milivolt, of\n",
    "    160 JJ wave, linear\n",
    "    161 Q wave, linear\n",
    "    162 R wave, linear\n",
    "    163 S wave, linear\n",
    "    164 R' wave, linear\n",
    "    165 S' wave, linear\n",
    "    166 P wave, linear\n",
    "    167 T wave, linear\n",
    "\n",
    "    168 QRSA , Sum of areas of all segments divided by 10, ( Area= width * height / 2 ), linear\n",
    "    169 QRSTA = QRSA + 0.5 * width of T wave * 0.1 * height of T wave. (If T is diphasic then the bigger segment is considered), linear\n",
    "\n",
    "    Of channel DII:\n",
    "    170 .. 179\n",
    "    Of channel DIII:\n",
    "    180 .. 189\n",
    "    Of channel AVR:\n",
    "    190 .. 199\n",
    "    Of channel AVL:\n",
    "    200 .. 209\n",
    "    Of channel AVF:\n",
    "    210 .. 219\n",
    "    Of channel V1:\n",
    "    220 .. 229\n",
    "    Of channel V2:\n",
    "    230 .. 239\n",
    "    Of channel V3:\n",
    "    240 .. 249\n",
    "    Of channel V4:\n",
    "    250 .. 259\n",
    "    Of channel V5:\n",
    "    260 .. 269\n",
    "    Of channel V6:\n",
    "    270 .. 279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global variables and constants\n",
    "DATA_FILENAME = 'arrhythmia.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_FILENAME, index_col = False, header=None, na_values = ['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 452 entries, 0 to 451\n",
      "Columns: 280 entries, 0 to 279\n",
      "dtypes: float64(125), int64(155)\n",
      "memory usage: 992.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452</td>\n",
       "      <td>46.471239</td>\n",
       "      <td>16.466631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.000</td>\n",
       "      <td>47.00</td>\n",
       "      <td>58.000</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>452</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452</td>\n",
       "      <td>166.188053</td>\n",
       "      <td>37.170340</td>\n",
       "      <td>105.0</td>\n",
       "      <td>160.000</td>\n",
       "      <td>164.00</td>\n",
       "      <td>170.000</td>\n",
       "      <td>780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>452</td>\n",
       "      <td>68.170354</td>\n",
       "      <td>16.590803</td>\n",
       "      <td>6.0</td>\n",
       "      <td>59.000</td>\n",
       "      <td>68.00</td>\n",
       "      <td>79.000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452</td>\n",
       "      <td>88.920354</td>\n",
       "      <td>15.364394</td>\n",
       "      <td>55.0</td>\n",
       "      <td>80.000</td>\n",
       "      <td>86.00</td>\n",
       "      <td>94.000</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>452</td>\n",
       "      <td>155.152655</td>\n",
       "      <td>44.842283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.000</td>\n",
       "      <td>157.00</td>\n",
       "      <td>175.000</td>\n",
       "      <td>524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>452</td>\n",
       "      <td>367.207965</td>\n",
       "      <td>33.385421</td>\n",
       "      <td>232.0</td>\n",
       "      <td>350.000</td>\n",
       "      <td>367.00</td>\n",
       "      <td>384.000</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>452</td>\n",
       "      <td>169.949115</td>\n",
       "      <td>35.633072</td>\n",
       "      <td>108.0</td>\n",
       "      <td>148.000</td>\n",
       "      <td>162.00</td>\n",
       "      <td>179.000</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>452</td>\n",
       "      <td>90.004425</td>\n",
       "      <td>25.826643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.000</td>\n",
       "      <td>91.00</td>\n",
       "      <td>102.000</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>452</td>\n",
       "      <td>33.676991</td>\n",
       "      <td>45.431434</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>3.750</td>\n",
       "      <td>40.00</td>\n",
       "      <td>66.000</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>444</td>\n",
       "      <td>36.150901</td>\n",
       "      <td>57.858255</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>14.000</td>\n",
       "      <td>41.00</td>\n",
       "      <td>63.250</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>430</td>\n",
       "      <td>48.913953</td>\n",
       "      <td>29.346409</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>41.000</td>\n",
       "      <td>56.00</td>\n",
       "      <td>65.000</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>451</td>\n",
       "      <td>36.716186</td>\n",
       "      <td>36.020725</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>12.000</td>\n",
       "      <td>40.00</td>\n",
       "      <td>62.000</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>76</td>\n",
       "      <td>-13.592105</td>\n",
       "      <td>127.220248</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-124.500</td>\n",
       "      <td>-50.50</td>\n",
       "      <td>117.250</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>451</td>\n",
       "      <td>74.463415</td>\n",
       "      <td>13.870684</td>\n",
       "      <td>44.0</td>\n",
       "      <td>65.000</td>\n",
       "      <td>72.00</td>\n",
       "      <td>81.000</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>452</td>\n",
       "      <td>5.628319</td>\n",
       "      <td>10.650001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.000</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>452</td>\n",
       "      <td>51.628319</td>\n",
       "      <td>18.249901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000</td>\n",
       "      <td>48.00</td>\n",
       "      <td>60.000</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>452</td>\n",
       "      <td>20.920354</td>\n",
       "      <td>20.541728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>36.000</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>452</td>\n",
       "      <td>0.141593</td>\n",
       "      <td>1.569483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>452</td>\n",
       "      <td>30.035398</td>\n",
       "      <td>10.046393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000</td>\n",
       "      <td>28.00</td>\n",
       "      <td>36.000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>452</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.047036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>452</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>0.104708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>452</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>0.104708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>452</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>452</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>452</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.093759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>452</td>\n",
       "      <td>5.619469</td>\n",
       "      <td>11.220680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>452</td>\n",
       "      <td>54.336283</td>\n",
       "      <td>17.248213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.000</td>\n",
       "      <td>48.00</td>\n",
       "      <td>64.000</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>452</td>\n",
       "      <td>20.592920</td>\n",
       "      <td>21.061050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>36.000</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>452</td>\n",
       "      <td>-0.297566</td>\n",
       "      <td>1.758544</td>\n",
       "      <td>-20.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>452</td>\n",
       "      <td>11.839381</td>\n",
       "      <td>5.917391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.875</td>\n",
       "      <td>11.20</td>\n",
       "      <td>15.100</td>\n",
       "      <td>36.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>452</td>\n",
       "      <td>-7.034513</td>\n",
       "      <td>5.061472</td>\n",
       "      <td>-42.9</td>\n",
       "      <td>-9.100</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>-3.700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>452</td>\n",
       "      <td>0.025664</td>\n",
       "      <td>0.166763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>452</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>0.046287</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>452</td>\n",
       "      <td>0.547788</td>\n",
       "      <td>0.426941</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>452</td>\n",
       "      <td>2.535841</td>\n",
       "      <td>2.429776</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>1.100</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.900</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>452</td>\n",
       "      <td>10.081195</td>\n",
       "      <td>25.074695</td>\n",
       "      <td>-124.8</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>11.40</td>\n",
       "      <td>25.050</td>\n",
       "      <td>103.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>452</td>\n",
       "      <td>33.328540</td>\n",
       "      <td>34.361665</td>\n",
       "      <td>-161.4</td>\n",
       "      <td>11.275</td>\n",
       "      <td>32.75</td>\n",
       "      <td>52.325</td>\n",
       "      <td>182.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>452</td>\n",
       "      <td>-0.285398</td>\n",
       "      <td>0.675060</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>452</td>\n",
       "      <td>-0.277212</td>\n",
       "      <td>0.992472</td>\n",
       "      <td>-14.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>452</td>\n",
       "      <td>11.369912</td>\n",
       "      <td>4.793656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.100</td>\n",
       "      <td>11.00</td>\n",
       "      <td>14.125</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>452</td>\n",
       "      <td>-3.607522</td>\n",
       "      <td>2.850633</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>-4.725</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-1.900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>452</td>\n",
       "      <td>0.016814</td>\n",
       "      <td>0.275907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>452</td>\n",
       "      <td>0.546681</td>\n",
       "      <td>0.370548</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>452</td>\n",
       "      <td>1.722124</td>\n",
       "      <td>1.708190</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.800</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>452</td>\n",
       "      <td>17.840044</td>\n",
       "      <td>16.445472</td>\n",
       "      <td>-56.8</td>\n",
       "      <td>8.675</td>\n",
       "      <td>18.35</td>\n",
       "      <td>27.900</td>\n",
       "      <td>82.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>452</td>\n",
       "      <td>32.871460</td>\n",
       "      <td>24.421643</td>\n",
       "      <td>-63.6</td>\n",
       "      <td>15.375</td>\n",
       "      <td>30.35</td>\n",
       "      <td>48.100</td>\n",
       "      <td>127.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>452</td>\n",
       "      <td>-0.302434</td>\n",
       "      <td>0.603551</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>452</td>\n",
       "      <td>-0.278982</td>\n",
       "      <td>0.548876</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>452</td>\n",
       "      <td>9.048009</td>\n",
       "      <td>3.472862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.600</td>\n",
       "      <td>8.80</td>\n",
       "      <td>11.200</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>452</td>\n",
       "      <td>-1.457301</td>\n",
       "      <td>2.002430</td>\n",
       "      <td>-28.6</td>\n",
       "      <td>-2.100</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>452</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>452</td>\n",
       "      <td>0.514823</td>\n",
       "      <td>0.347531</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>452</td>\n",
       "      <td>1.222345</td>\n",
       "      <td>1.426052</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.100</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>452</td>\n",
       "      <td>19.326106</td>\n",
       "      <td>13.503922</td>\n",
       "      <td>-44.2</td>\n",
       "      <td>11.450</td>\n",
       "      <td>18.10</td>\n",
       "      <td>25.825</td>\n",
       "      <td>88.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>452</td>\n",
       "      <td>29.473230</td>\n",
       "      <td>18.493927</td>\n",
       "      <td>-38.6</td>\n",
       "      <td>17.550</td>\n",
       "      <td>27.90</td>\n",
       "      <td>41.125</td>\n",
       "      <td>115.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>452</td>\n",
       "      <td>3.880531</td>\n",
       "      <td>4.407097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     count        mean         std    min      25%     50%      75%    max\n",
       "0      452   46.471239   16.466631    0.0   36.000   47.00   58.000   83.0\n",
       "1      452    0.550885    0.497955    0.0    0.000    1.00    1.000    1.0\n",
       "2      452  166.188053   37.170340  105.0  160.000  164.00  170.000  780.0\n",
       "3      452   68.170354   16.590803    6.0   59.000   68.00   79.000  176.0\n",
       "4      452   88.920354   15.364394   55.0   80.000   86.00   94.000  188.0\n",
       "5      452  155.152655   44.842283    0.0  142.000  157.00  175.000  524.0\n",
       "6      452  367.207965   33.385421  232.0  350.000  367.00  384.000  509.0\n",
       "7      452  169.949115   35.633072  108.0  148.000  162.00  179.000  381.0\n",
       "8      452   90.004425   25.826643    0.0   79.000   91.00  102.000  205.0\n",
       "9      452   33.676991   45.431434 -172.0    3.750   40.00   66.000  169.0\n",
       "10     444   36.150901   57.858255 -177.0   14.000   41.00   63.250  179.0\n",
       "11     430   48.913953   29.346409 -170.0   41.000   56.00   65.000  176.0\n",
       "12     451   36.716186   36.020725 -135.0   12.000   40.00   62.000  166.0\n",
       "13      76  -13.592105  127.220248 -179.0 -124.500  -50.50  117.250  178.0\n",
       "14     451   74.463415   13.870684   44.0   65.000   72.00   81.000  163.0\n",
       "15     452    5.628319   10.650001    0.0    0.000    0.00   12.000   88.0\n",
       "16     452   51.628319   18.249901    0.0   40.000   48.00   60.000  156.0\n",
       "17     452   20.920354   20.541728    0.0    0.000   20.00   36.000   88.0\n",
       "18     452    0.141593    1.569483    0.0    0.000    0.00    0.000   24.0\n",
       "19     452    0.000000    0.000000    0.0    0.000    0.00    0.000    0.0\n",
       "20     452   30.035398   10.046393    0.0   24.000   28.00   36.000  100.0\n",
       "21     452    0.002212    0.047036    0.0    0.000    0.00    0.000    1.0\n",
       "22     452    0.011062    0.104708    0.0    0.000    0.00    0.000    1.0\n",
       "23     452    0.011062    0.104708    0.0    0.000    0.00    0.000    1.0\n",
       "24     452    0.004425    0.066445    0.0    0.000    0.00    0.000    1.0\n",
       "25     452    0.004425    0.066445    0.0    0.000    0.00    0.000    1.0\n",
       "26     452    0.008850    0.093759    0.0    0.000    0.00    0.000    1.0\n",
       "27     452    5.619469   11.220680    0.0    0.000    0.00    0.000   76.0\n",
       "28     452   54.336283   17.248213    0.0   44.000   48.00   64.000  132.0\n",
       "29     452   20.592920   21.061050    0.0    0.000   20.00   36.000   92.0\n",
       "..     ...         ...         ...    ...      ...     ...      ...    ...\n",
       "250    452   -0.297566    1.758544  -20.4    0.000    0.00    0.000    0.0\n",
       "251    452   11.839381    5.917391    0.0    7.875   11.20   15.100   36.4\n",
       "252    452   -7.034513    5.061472  -42.9   -9.100   -6.00   -3.700    0.0\n",
       "253    452    0.025664    0.166763    0.0    0.000    0.00    0.000    2.4\n",
       "254    452   -0.002876    0.046287   -0.9    0.000    0.00    0.000    0.0\n",
       "255    452    0.547788    0.426941   -2.6    0.400    0.60    0.800    2.8\n",
       "256    452    2.535841    2.429776   -8.2    1.100    2.40    3.900   15.6\n",
       "257    452   10.081195   25.074695 -124.8   -0.925   11.40   25.050  103.4\n",
       "258    452   33.328540   34.361665 -161.4   11.275   32.75   52.325  182.3\n",
       "259    452   -0.285398    0.675060   -4.8   -0.600   -0.20    0.000    3.4\n",
       "260    452   -0.277212    0.992472  -14.2    0.000    0.00    0.000    0.0\n",
       "261    452   11.369912    4.793656    0.0    8.100   11.00   14.125   29.5\n",
       "262    452   -3.607522    2.850633  -30.8   -4.725   -3.00   -1.900    0.0\n",
       "263    452    0.016814    0.275907    0.0    0.000    0.00    0.000    5.8\n",
       "264    452    0.000000    0.000000    0.0    0.000    0.00    0.000    0.0\n",
       "265    452    0.546681    0.370548   -0.9    0.400    0.60    0.700    2.8\n",
       "266    452    1.722124    1.708190   -5.0    0.700    1.75    2.800    8.3\n",
       "267    452   17.840044   16.445472  -56.8    8.675   18.35   27.900   82.1\n",
       "268    452   32.871460   24.421643  -63.6   15.375   30.35   48.100  127.9\n",
       "269    452   -0.302434    0.603551   -5.6   -0.500   -0.20    0.000    2.7\n",
       "270    452   -0.278982    0.548876   -4.1   -0.425    0.00    0.000    0.0\n",
       "271    452    9.048009    3.472862    0.0    6.600    8.80   11.200   23.6\n",
       "272    452   -1.457301    2.002430  -28.6   -2.100   -1.10    0.000    0.0\n",
       "273    452    0.003982    0.050118    0.0    0.000    0.00    0.000    0.8\n",
       "274    452    0.000000    0.000000    0.0    0.000    0.00    0.000    0.0\n",
       "275    452    0.514823    0.347531   -0.8    0.400    0.50    0.700    2.4\n",
       "276    452    1.222345    1.426052   -6.0    0.500    1.35    2.100    6.0\n",
       "277    452   19.326106   13.503922  -44.2   11.450   18.10   25.825   88.8\n",
       "278    452   29.473230   18.493927  -38.6   17.550   27.90   41.125  115.9\n",
       "279    452    3.880531    4.407097    1.0    1.000    1.00    6.000   16.0\n",
       "\n",
       "[280 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   270  271  272  273  \\\n",
       "0   75    0  190   80   91  193  371  174  121  -16 ...     0  9.0 -0.9    0   \n",
       "1   56    1  165   64   81  174  401  149   39   25 ...     0  8.5  0.0    0   \n",
       "\n",
       "   274  275  276   277   278  279  \n",
       "0    0  0.9  2.9  23.3  49.4    8  \n",
       "1    0  0.2  2.1  20.4  38.8    6  \n",
       "\n",
       "[2 rows x 280 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>-17</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  11  12  13\n",
       "0  13  64  -2 NaN\n",
       "1  37 -17  31 NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0:2, 10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1], data.iloc[:, -1], test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316, 279)\n",
      "(316,)\n",
      "(136, 279)\n",
      "(136,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clf = KMeans(n_clusters = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=16, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  8, 15,  0,  0,  0,  3,  0,  1, 22,  4, 17,  0,  0],\n",
       "       [ 3,  1,  3,  4,  0,  0,  0,  1,  0,  0,  1,  0,  2,  1,  0],\n",
       "       [ 4,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0],\n",
       "       [ 0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  1,  2,  1,  0,  0,  0,  1,  0,  0,  3,  0,  2,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  1,  0,  0],\n",
       "       [ 1,  0,  6,  0,  0,  0,  0,  2,  0,  0,  1,  0,  3,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  2,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  2,  0,  0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022058823529411766"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71323529411764708"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69  2  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 5  9  0  1  0  0  0  0  1  0  0  0]\n",
      " [ 1  0  5  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  1  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  1  0  0  0  0  0  1  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  4  0  0  0  0]\n",
      " [ 4  1  0  0  0  0  0  0  8  0  0  0]\n",
      " [ 2  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  1  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.96      0.82        72\n",
      "          2       0.69      0.56      0.62        16\n",
      "          3       0.71      0.83      0.77         6\n",
      "          4       0.67      0.67      0.67         3\n",
      "          5       0.00      0.00      0.00         3\n",
      "          6       0.00      0.00      0.00        10\n",
      "          7       0.00      0.00      0.00         1\n",
      "          9       1.00      1.00      1.00         4\n",
      "         10       0.67      0.62      0.64        13\n",
      "         14       0.00      0.00      0.00         3\n",
      "         15       0.00      0.00      0.00         1\n",
      "         16       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.60      0.71      0.64       136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(X_train, label= y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_test = xgb.DMatrix(X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'multi:softmax', 'num_class': 17}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, xgb_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = gbm.predict(xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71323529411764708"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  4  0  0  1  0  0  0  2  0  0  0]\n",
      " [ 4  9  0  0  0  0  0  0  2  0  1  0]\n",
      " [ 1  0  5  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  0  0  1  0  0  0]\n",
      " [ 3  0  1  0  0  6  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  3  0  0  0  0]\n",
      " [ 4  0  0  0  1  1  0  0  7  0  0  0]\n",
      " [ 2  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  1  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/collections.py:548: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAHRCAYAAADqjfmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93beb32090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.unique(y_test)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "plt.xticks(range(len(labels)), labels)\n",
    "plt.yticks(range(len(labels)), labels)\n",
    "#ax.set_xticklabels(labels)\n",
    "#ax.set_yticklabels(labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.90      0.82        72\n",
      "          2       0.64      0.56      0.60        16\n",
      "          3       0.71      0.83      0.77         6\n",
      "          4       1.00      0.33      0.50         3\n",
      "          5       0.33      0.33      0.33         3\n",
      "          6       0.75      0.60      0.67        10\n",
      "          7       0.00      0.00      0.00         1\n",
      "          9       1.00      0.75      0.86         4\n",
      "         10       0.58      0.54      0.56        13\n",
      "         14       0.00      0.00      0.00         3\n",
      "         15       0.00      0.00      0.00         1\n",
      "         16       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.67      0.71      0.68       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to optimize for recall, because we want to minimize the number of persons who have arrhythmia and our classifier don't detect.\n",
    "\n",
    "Recall = TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'multi:softmax', 'num_class': 17, 'eval_metric':['auc', 'merror'], 'max_delta_step': 1, 'max_depth': 10, 'eta': 0.7, 'gamma': 0, 'min_child_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, xgb_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = gbm.predict(xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  4  0  1  0  0  0  0  2  0  0  0]\n",
      " [ 5  8  0  0  0  0  0  0  2  0  1  0]\n",
      " [ 0  1  5  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  8  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  3  0  0  0  0]\n",
      " [ 3  0  0  1  0  1  0  0  7  0  0  1]\n",
      " [ 2  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 3  0  1  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.82      0.90      0.86        72\n",
      "          2       0.57      0.50      0.53        16\n",
      "          3       0.71      0.83      0.77         6\n",
      "          4       0.60      1.00      0.75         3\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       0.80      0.80      0.80        10\n",
      "          7       0.00      0.00      0.00         1\n",
      "          9       1.00      0.75      0.86         4\n",
      "         10       0.58      0.54      0.56        13\n",
      "         14       0.00      0.00      0.00         3\n",
      "         15       0.00      0.00      0.00         1\n",
      "         16       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.71      0.75      0.73       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
